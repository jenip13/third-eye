# Construct-I
Project for the 2018 AI for Social Good Hackathon

We have built and trained a model to recognize the construction sites that are found at every street corner here in Montreal, aimed to aid the mobility visually impaired within the city. The purpose of the app is to inform blind people when they are approaching a construction site so they don't run into it, fall into it, or get themselves hurt. In the future, we could expand this to detect various other features in a city, such as stoplights, pedestrian walklights, other people, buildings, and cars. 


By creating our own dataset with 67 images of construction sites and 68 no-contruction sites in Montreal, we were able to train and test our model using convoluted neural networks and reached an accuracy of approximatly 77%. 

Our model should be able to detect the incoming image of construction sites and alert the user that the front path is a "no go" and that they should try another path. 

Here is our pitch: https://docs.google.com/presentation/d/1IVlg-DR9DB8k7RDneLAOgExkHa_rkLhPxSgswEMItyg/edit?usp=sharing

# Credits
Source for backend model: https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d

Source for frontend model:https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html
